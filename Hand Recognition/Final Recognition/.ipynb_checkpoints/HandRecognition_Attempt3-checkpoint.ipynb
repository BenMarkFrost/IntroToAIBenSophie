{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import imutils\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model Model Versions/HandModelV5.h5\n"
     ]
    }
   ],
   "source": [
    "def loadModel():\n",
    "    \n",
    "    version = 0\n",
    "    modelDir = \"Model Versions/HandModelV\"\n",
    "\n",
    "    # This method always gets the most up to date model.\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            version = version + 1\n",
    "            f = open(modelDir + str(version) + \".h5\", 'r')\n",
    "            f.close()\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    model = keras.models.load_model(modelDir + str(version-1) + \".h5\")\n",
    "    \n",
    "    print(\"Using model \" + modelDir + str(version-1) + \".h5\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setUseOptimized(True);\n",
    "cv2.setNumThreads(4);\n",
    "\n",
    "version = 1\n",
    "dir = \"../../../../HandsData/OpenCVHandsData/None/none\"\n",
    "\n",
    "def saveImage(handBox):\n",
    "\n",
    "    global version\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            f = open(dir + str(version) + \".jpg\", 'r')\n",
    "            f.close()\n",
    "            version = version + 1\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        cv2.imwrite(dir + str(version) + \".jpg\", handBox)\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeX = 60\n",
    "sizeY = 100\n",
    "\n",
    "def resize(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, ch = image.shape\n",
    "    \n",
    "    zeros = np.zeros((sizeY, sizeX, 3))\n",
    "    \n",
    "    tempImage = image.copy()\n",
    "    \n",
    "    image = imutils.resize(tempImage, height=sizeY)\n",
    "    if image.shape[1] > sizeX:\n",
    "        image = imutils.resize(tempImage, width=sizeX)\n",
    "    \n",
    "    zeros[:image.shape[0], :image.shape[1]] = image\n",
    "    \n",
    "    \n",
    "    \n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputText = \"\"\n",
    "combinedOutput = []\n",
    "\n",
    "def classifyHand(handBox):\n",
    "    \n",
    "    global outputText, combinedOutput\n",
    "    \n",
    "    try :\n",
    "        handBox = resize(handBox)\n",
    "    except:\n",
    "        print(\"Mitigating error\") # (Nobody will notice :) )\n",
    "        return outputText, combinedOutput\n",
    "    \n",
    "    handBox = np.array(handBox)\n",
    "        \n",
    "    pred_hot = model.predict(np.expand_dims(handBox, axis=0))[0]\n",
    "\n",
    "    \n",
    "    if pred_hot[0] > pred_hot[1]:\n",
    "        outputText = \"Index \"\n",
    "    else:\n",
    "        outputText = \"Fist \"\n",
    "    \n",
    "    \n",
    "    combinedOutput = [\"Fist: \" + str(pred_hot[1]), \"Index \" + str(pred_hot[0])]\n",
    "    \n",
    "    return outputText, combinedOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeBackground(frame):\n",
    "\n",
    "    background = cv2.createBackgroundSubtractorMOG2(0,50)\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "    bgMask = background.apply(frame)\n",
    "    bgMask = cv2.erode(bgMask, kernel, iterations=1)\n",
    "\n",
    "    return cv2.bitwise_and(frame, frame, mask = bgMask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 60, 100, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 60, 100, 3), dtype=tf.float32, name='conv2d_40_input'), name='conv2d_40_input', description=\"created by layer 'conv2d_40_input'\"), but it was called on an input with incompatible shape (None, 100, 60, 3).\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n",
      "Too close\n",
      "Mitigating error\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    frame = cv2.bilateralFilter(frame, 5, 50, 100)  # Smoothing\n",
    "    \n",
    "    mask = removeBackground(frame)\n",
    "\n",
    "    \n",
    "    # Detecting skin\n",
    "\n",
    "    hsv = cv2.cvtColor(mask, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([0,48,80], dtype=\"uint8\")\n",
    "    upper = np.array([20,255,255], dtype=\"uint8\")\n",
    "    skinMask = cv2.inRange(hsv, lower, upper)\n",
    "    \n",
    "    \n",
    "    #Find contours in the image\n",
    "    \n",
    "    contours, heirarchy = cv2.findContours(skinMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    areas = []\n",
    "    \n",
    "    if len(contours) > 0:\n",
    "        \n",
    "        for contour in contours:\n",
    "            \n",
    "            areas.append(cv2.contourArea(contour))\n",
    "        \n",
    "        maxCon = max(areas)\n",
    "        \n",
    "        # Finding the biggest contour found by OpenCV\n",
    "        \n",
    "        res = contours[areas.index(maxCon)]\n",
    "    \n",
    "        x, y, w, h = cv2.boundingRect(res)\n",
    "               \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Adding padding around the box of interest. This will fail if it is too close to the edge.\n",
    "            \n",
    "            handBox = frame[int(y-h/4):int(y+h*1.25), int(x-w/4):int(x+w*1.25)]\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            \n",
    "            # If the hand is at the edge of the screen no padding is applied\n",
    "            \n",
    "            handBox = frame[y:y+h, x:x+w]\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # If the user's hand is too close to the screen, \n",
    "            # the box around the hand that was generated by \n",
    "            # OpenCV will be taller than the frame, which causes this to fail.\n",
    "            \n",
    "            cv2.imshow(\"Box\", handBox)\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            print(\"Too close\")\n",
    "        \n",
    "        \n",
    "        # Adding the box around the hand\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                \n",
    "            \n",
    "        # saveImage() is used for collecting images for training the classifier. \n",
    "        # We only ever want to be either saving the images or classifying them directly.\n",
    "        \n",
    "        save = false\n",
    "        \n",
    "        if save:\n",
    "            \n",
    "            saveImage(handBox)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Two outputs from the classifier function - a verbose version and a long version.\n",
    "            outputText, combinedOutput = classifyHand(handBox)\n",
    "\n",
    "            # Printing the results of the classifier in the top left corner.\n",
    "            # This is looped so that more classes can be added to the model in the future.\n",
    "            spacing = 25\n",
    "            for i in range(len(combinedOutput)):\n",
    "                cv2.putText(frame, combinedOutput[i], (10, 25 + (i * spacing)), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Adding the label on the hand itself.\n",
    "            cv2.putText(frame, outputText, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Output\", frame)\n",
    "        \n",
    "    \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
