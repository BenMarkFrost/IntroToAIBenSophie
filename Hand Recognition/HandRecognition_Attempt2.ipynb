{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import imutils\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1\n",
    "# Create a setup screen, showing hand on screen to set the right threshold?\n",
    "# User can move sliders to set the correct threshold\n",
    "# Include blown out hands\n",
    "\n",
    "# 2\n",
    "# Remove face in video?\n",
    "\n",
    "# 3\n",
    "# Multithreading for better performance\n",
    "\n",
    "# 4\n",
    "# Write about smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model Model Versions/HandModelV1.h5\n"
     ]
    }
   ],
   "source": [
    "def loadModel():\n",
    "    \n",
    "    version = 0\n",
    "    modelDir = \"Model Versions/HandModelV\"\n",
    "\n",
    "    # This method always gets the most up to date model.\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            version = version + 1\n",
    "            f = open(modelDir + str(version) + \".h5\", 'r')\n",
    "            f.close()\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    model = keras.models.load_model(modelDir + str(version-1) + \".h5\")\n",
    "    \n",
    "    print(\"Using model \" + modelDir + str(version-1) + \".h5\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setUseOptimized(True);\n",
    "cv2.setNumThreads(4);\n",
    "\n",
    "version = 1\n",
    "dir = \"../../../../HandsData/OpenCVHandsData/One/Me/Second/2one\"\n",
    "\n",
    "def saveImage(handBox):\n",
    "                \n",
    "    global version\n",
    "        \n",
    "    while True:\n",
    "        try:\n",
    "            f = open(dir + str(version) + \".jpg\", 'r')\n",
    "            f.close()\n",
    "            version = version + 1\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        cv2.imwrite(dir + 1 + \".jpg\", handBox)\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeX = 60\n",
    "sizeY = 100\n",
    "\n",
    "def resize(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, ch = image.shape\n",
    "    \n",
    "    zeros = np.zeros((sizeY, sizeX, 3))\n",
    "    \n",
    "    tempImage = image.copy()\n",
    "    \n",
    "    #Apparently there's a bug in OpenCV that causes the program to crash if the resized image is too large.\n",
    "    \n",
    "    image = imutils.resize(tempImage, height=sizeY)\n",
    "    if image.shape[1] > sizeX:\n",
    "        image = imutils.resize(tempImage, width=sizeX)\n",
    "\n",
    "    zeros[:image.shape[0], :image.shape[1]] = image    \n",
    "    \n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputText = \"\"\n",
    "combinedOutput = []\n",
    "\n",
    "def classifyHand(handBox):\n",
    "    \n",
    "    global outputText, combinedOutput\n",
    "    \n",
    "    try :\n",
    "        handBox = resize(handBox)\n",
    "    except:\n",
    "        print(\"Mitigating error\") # (Nobody will notice :) )\n",
    "        return outputText, combinedOutput\n",
    "    \n",
    "#     plt.imshow(handBox)\n",
    "#     plt.show()\n",
    "    \n",
    "    handBox = np.array(handBox)\n",
    "        \n",
    "    pred_hot = model.predict(np.expand_dims(handBox, axis=0))[0]\n",
    "\n",
    "    \n",
    "    if pred_hot[0] > pred_hot[1]:\n",
    "        outputText = \"Index \" + str(pred_hot[0])\n",
    "    else:\n",
    "        outputText = \"Fist \" + str(pred_hot[1])\n",
    "    \n",
    "    \n",
    "    combinedOutput = [\"Fist: \" + str(pred_hot[1]), \"Index \" + str(pred_hot[0])]\n",
    "    \n",
    "    return outputText, combinedOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 60, 100, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 60, 100, 3), dtype=tf.float32, name='conv2d_30_input'), name='conv2d_30_input', description=\"created by layer 'conv2d_30_input'\"), but it was called on an input with incompatible shape (None, 100, 60, 3).\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    frame = cv2.bilateralFilter(frame, 5, 50, 100)  # Smoothing\n",
    "\n",
    "#     cv2.imshow(\"Output\", frame)\n",
    "\n",
    "    # Removing background\n",
    "\n",
    "    background = cv2.createBackgroundSubtractorMOG2(0,50)\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "    bgMask = background.apply(frame)\n",
    "    bgMask = cv2.erode(bgMask, kernel, iterations=1)\n",
    "\n",
    "    mask = cv2.bitwise_and(frame, frame, mask = bgMask)\n",
    "    \n",
    "    \n",
    "    # Detecting skin\n",
    "\n",
    "    hsv = cv2.cvtColor(mask, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([0,48,80], dtype=\"uint8\")\n",
    "    upper = np.array([20,255,255], dtype=\"uint8\")\n",
    "    skinMask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    #cv2.imshow(\"Threshold\", skinMask)\n",
    "\n",
    "    # Contours\n",
    "\n",
    "#     skinMask = skinMask.copy()\n",
    "\n",
    "    contours, heirarchy = cv2.findContours(skinMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) > 0:\n",
    "        maxArea = -1\n",
    "        for i in range(len(contours)):\n",
    "            area = cv2.contourArea(contours[i])\n",
    "            if area > maxArea:\n",
    "                maxArea = area\n",
    "                res = contours[i]\n",
    "    \n",
    "        hull = cv2.convexHull(res)\n",
    "        drawing = np.zeros(mask.shape, np.uint8)\n",
    "        #res is outline of hand\n",
    "        cv2.drawContours(drawing, [res], 0, (0, 255, 0), 2)\n",
    "        #hull is box around hand\n",
    "        cv2.drawContours(drawing, [hull], 0, (0, 0, 255), 3)\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(res)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Adding padding around the box of interest. If the hand is at the edge of the screen this won't work.\n",
    "            \n",
    "            handBox = frame[int(y-h/4):int(y+h*1.25), int(x-w/4):int(x+w*1.25)]\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            \n",
    "            handBox = frame[y:y+h, x:x+w]\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            cv2.imshow(\"Box\", handBox)\n",
    "        except:\n",
    "            print(\"Too close\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        # saveImage is used for collecting images for training the classifier\n",
    "\n",
    "        #saveImage(handBox)\n",
    "\n",
    "        \n",
    "        cv2.rectangle(frame, (int(x-w/4), int(y-h/4)), (int(x+w*1.25), int(y+h*1.25)), (0, 0, 255), 2)\n",
    "        \n",
    "\n",
    "        #print(model.predict(np.expand_dims(resize(handBox), axis=0))[0])\n",
    "                \n",
    "        \n",
    "        outputText, combinedOutput = classifyHand(handBox)\n",
    "        \n",
    "        spacing = 25\n",
    "        for i in range(len(combinedOutput)):\n",
    "            cv2.putText(frame, combinedOutput[i], (10, 25 + (i * spacing)), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(frame, outputText, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(\"Output\", frame)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        cv2.imshow(\"Output\", frame)\n",
    "\n",
    "        \n",
    "    \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
